{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9806c444",
   "metadata": {},
   "source": [
    "# Изменение порядка слов в предложении при переводе (или до перевода)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df5674b",
   "metadata": {},
   "source": [
    "При переводе, как правило, синтаксическая структура предложения меняется (т.е. перевод не только отображает \"английские\" слова в \"русские\", но и меняет их местами; некоторые слова могут исчезнуть или, наоборот, появиться).\n",
    "\n",
    "Меня интересует разница синтаксиса между различными славянскими языками -- их синтаксис достаточно близок друг к другу, но при этом существует множество нюансов (как описанных в литературе, так и нет).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4258da69",
   "metadata": {},
   "source": [
    "## Мотивация\n",
    "\n",
    "Моё хобби -- это разработка NLP-инструментов для межславянского искусственного языка. Межславянскы језык јест језык, разумливы приблизно всим словјанам без ученја (грубо говоря, можно назвать его \"славянским Эсперанто\").\n",
    "\n",
    "В основном он добивается своей цели посредством тщательно курированного словосбора, но также важными являются грамматика и фонетика. Нажалость, спецификации синтаксиса для него практически не существует: учебники ограничиваются фразами типа \"порядок слов обычно Subject Verb Object\", но на самом деле очень многое остаётся недосказанным. Синтаксис (т.е. порядок слов) влияет на понятность и на степень того, насколько скрипят мозги у читателя/слушателя.\n",
    "\n",
    "Этот проект посвящён некоторым аспектам славянских языков с прицелом на то, как адаптировать синтаксис данного природного языка для того, чтобы увеличить его разумливость. Желательно, автоматически.\n",
    "\n",
    "Я попробую изучить эти явления при помощи модели `facebook/nllb-200-distilled-600M`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff01fae",
   "metadata": {},
   "source": [
    "## Вопрос 1: обнуление субъекта и копулы\n",
    "\n",
    "Воспроизводит ли NLLB-200 некоторые известные синтаксические явления?\n",
    "\n",
    "К числу наиболее частых явлений относится pro-drop (пропуск личных местоимений) и zero copula (опускание копулы, т.е. глагола-связки \"быть\").\n",
    "\n",
    "Эти аспекты ~~суть~~ проблематичны в контексте межславянского языка, потому что разные языки используют разные стратегии пропускания и это может привести к проблемам в понятности. Например, сравним пары чешских и русских предложений:\n",
    "\n",
    "> Мы ~~есть~~ довольны \n",
    "> \n",
    "> ~~My~~ Jsme spokojeni;  \n",
    "> \n",
    "> Я сегодня ~~есть~~ в школе \n",
    "> \n",
    "> ~~Já~~ Jsem dnes ve škole.\n",
    "> \n",
    "> А ты куда ~~идёшь~~? \n",
    "> \n",
    "> Kam ~~ty~~ jdeš?\n",
    "> \n",
    "> Вы когда ~~отправитесь~~ обратно? \n",
    "> \n",
    "> Kdy ~~vy~~ se vracíte?\n",
    "\n",
    "или следующее польское предложение:\n",
    "\n",
    "> Wiedziałem, że do nas wrócisz\n",
    "> \n",
    "> знал_есмь, что к нам вернёшь\n",
    "> \n",
    "> \"~~Я~~ знал, что ~~ты~~ к нам вернешься\"\n",
    "\n",
    "Видно, что чешская стратегия построения коротких предложений (пропуск местоимений) в каком-то смысле является противоположностью русской стратегии пропуска глаголов.\n",
    "\n",
    "Также в западнославянских языках можно опускать местоименное подлежащее, относящееся к только что упомянутому субъекту. Обе эти фразы на польском являются допустимыми:\n",
    "\n",
    "> Piotr spotkał Ewę. Ona powiedziała mu, że...\n",
    "> \n",
    "> Piotr spotkał Ewę. Powiedziała mu, że...\n",
    "\n",
    "В то же время в русском языке пропуск местоимения \"она\" практически немыслим.\n",
    "\n",
    "> Пётр встретил Наташу. Она рассказала ему, что...\n",
    "\n",
    "\n",
    "### пропуск местоимений\n",
    "\n",
    "Если говорить о природных славянских языках, то вопрос пропуска местоимений/предикатов можно назвать умозрительным. Однако в контексте межславянского этот вопрос ~~есть~~ действительно важный. ~~Я~~ приведу два реально встретившихся мне примера:\n",
    "\n",
    "Говоритель -- хорват.\n",
    "> Odlično, ja už jesm govoril s jim, ale ničto ne jest govoril\n",
    ">\n",
    "> \"Отлично, я уже говорил с ним, но ~~он~~ ничего не ответил\"\n",
    ">\n",
    "> \"Odlično, pitao sam ga, ali ~~on~~ nije odgovorio\"\n",
    "\n",
    "По правилам хорватского синтаксиса (как и межславянского) личное местоимение \"он\" здесь ~~есть~~ избыточно, поскольку нужная информация здесь передаётся вспомогательным глаголом `jest` (который изменяется по числам и лицам: ja jesm, ty jesi, on jest; можно провести аналогию с русским \"я иду\", которое без потери информации можно сократить до просто \"иду\"). Тем не менее, это вызывает проблемы с пониманием из-за своей непривычности.\n",
    "\n",
    "(также интересно сравнить с \"я уже с ней говорил, но ничего не рассказала\")\n",
    "\n",
    "Зеркальный пример, где говоритель -- русскоговорящий.\n",
    "\n",
    "> Odpisal tobě privatno\n",
    ">\n",
    "> \"~~Я~~ ответил тебе приватно\"\n",
    ">\n",
    "> \"~~Ja~~ odgovorio sam ti privatno\"\n",
    "\n",
    "Фразы похожей конструкции часто встречаются в русском (и других восточнославянских языках): например, \"читал книгу\" или \"смотрел вчера интересный фильм\". Строго говоря, здесь уже грамматически невозможно восстановить пропущеного агента, коим может быть как \"я\", так и \"он\". Благодаря сложившейся традиции все русскоговорящие обычно понимают, что здесь подразумевается \"я\". \n",
    "\n",
    "Однако для западных и южных славян это в лучшем случае непонятно, в худшем вообще неграмматично. Я спросил нескольких южных славян по поводу этой фразы и пришёл к выводу, что без дополнительного контекста южане скорее подумают, что здесь пропущено местоимение \"он\".\n",
    "\n",
    "### пропуск копулы\n",
    "\n",
    "Это явление характерно для русского языка (а также, в чуть меньшей степени, для украинского и беларусского). Глагол-связка \"быть\" исчезает в настоящем времени, хотя существует в прошедшем и будущем:\n",
    "\n",
    "> Мне это было интересно. Он был студентом. (\"он был студент\" тоже допустимо)\n",
    "> \n",
    "> Мне это ~~есть~~ интересно. Он студент.\n",
    "> \n",
    "> Мне это будет интересно. Он будет студентом. (\"он будет студент\" тоже допустимо)\n",
    "\n",
    "Это затрудняет восприятие русского текста западными и южными славянами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77129e9d",
   "metadata": {},
   "source": [
    "### глаголы первого и третьего лица настоящего времени\n",
    "\n",
    "Дополнительную проблему вызывают глаголы в формах первого и третьего лица. Формально говоря, грамматика межславянского однозначно указывает на нужное местоимение:\n",
    "\n",
    "> Ja dělaju / ja dělam\n",
    "> \n",
    "> My dělajemo / my dělamo\n",
    "> \n",
    "> Oni delajut\n",
    "\n",
    "Однако на практике опускать местоимения не рекомендуется, поскольку снаружи межславянского однозначность разрушается. Примерно в половине славянских языков глаголы выглядят примерно как \"я делаю, мы делаем, они делают\", а в половине \"я делам, мы деламо, они делаю\".\n",
    "\n",
    "Таким образом, местоимение требуется даже в таких очевидно однозначных с точки зрения русского языка случаях как \"иду, вижу, слышу, читаю\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d636d17a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22660a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\", output_attentions=True, return_dict_in_generate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6327088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from razdel import sentenize\n",
    "\n",
    "def translate(text, src_lang, tgt_lang, **kwargs):\n",
    "    tokenizer.src_lang = src_lang\n",
    "    tokenizer.tgt_lang = tgt_lang\n",
    "    results = []\n",
    "    for sent in sentenize(text):\n",
    "        inputs = tokenizer(sent.text, return_tensors='pt')\n",
    "        result = model.generate(\n",
    "            **inputs.to(model.device), \n",
    "            forced_bos_token_id=tokenizer.convert_tokens_to_ids(tgt_lang),\n",
    "            **kwargs\n",
    "        )\n",
    "        results.append(\n",
    "            tokenizer.decode(result[0], skip_special_tokens=True)\n",
    "        )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37ddc2",
   "metadata": {},
   "source": [
    "NLLB200 позволяет переводить тексты с любого славянского языка на любой славянский без посредника в виде pivot language (например, английского)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "3b7f2efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bel\n",
      "['сэндвич з сальсамі']\n",
      "['Медведзь са мной']\n",
      "['выцярпеце са мной']\n",
      "ukr\n",
      "['сэндвич з лососями']\n",
      "['Медведь зі мною']\n",
      "['Витримай мене']\n",
      "rus\n",
      "['лосось-санск']\n",
      "['медведь со мной']\n",
      "['Будь со мной терпелив.']\n",
      "bos\n",
      "['sendvič sa zalosom']\n",
      "['Medved sa mnom.']\n",
      "['-Budi sa mnom.']\n",
      "hrv\n",
      "['Sjednica sa zalosom']\n",
      "['Medvjed sa mnom.']\n",
      "['-Budi strpljivi sa mnom.']\n",
      "srp\n",
      "['суствер са лососом']\n",
      "['Медвеђа са мном']\n",
      "['Држи ме са мном.']\n",
      "slv\n",
      "['sendvič z lasom']\n",
      "['Medved z mano.']\n",
      "['-Straj z mano.']\n",
      "bul\n",
      "['сандвич с лососи']\n",
      "['Мечката е с мен.']\n",
      "['- Не ме мърдай.']\n",
      "mkd\n",
      "['сандвич со лососи']\n",
      "['Мечката со мене.']\n",
      "['Држи се со мене.']\n",
      "pol\n",
      "['kanapki z łosośą']\n",
      "['niedźwiedź ze mną']\n",
      "['- Nie.']\n",
      "ces\n",
      "['sendvič s lososem']\n",
      "['medvěd se mnou.']\n",
      "['- Nechte mě být.']\n",
      "slk\n",
      "['sendvič s lososom']\n",
      "['medveď so mnou']\n",
      "['- Nechaj ma.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "SLAVIC_LANGS = [\n",
    "    'bel', 'ukr', 'rue', 'rus', 'bos', 'hrv', 'srp', 'cnr', 'slv', 'bul', 'mkd', 'chu', 'wen', 'dsb', 'hsb', 'pol', 'szl', 'csb', 'pox', 'ces', 'czk', 'slk',\n",
    "]\n",
    "\n",
    "\n",
    "ietf_bcp = {\n",
    "    'bel': \"bel_Cyrl\",\n",
    "    'ukr': \"ukr_Cyrl\",\n",
    "    'rue': None,\n",
    "    'rus': \"rus_Cyrl\",\n",
    "    'bos': \"bos_Latn\",\n",
    "    'hrv': \"hrv_Latn\",\n",
    "    'srp': \"srp_Cyrl\", \n",
    "    'cnr': None,\n",
    "    'slv': \"slv_Latn\",\n",
    "    'bul': \"bul_Cyrl\",\n",
    "    'mkd': \"mkd_Cyrl\",\n",
    "    'chu': None,\n",
    "    'wen': None,\n",
    "    'dsb': None,\n",
    "    'hsb': None,\n",
    "    'pol': \"pol_Latn\",\n",
    "    'szl': None,\n",
    "    'csb': None,\n",
    "    'pox': None,\n",
    "    'ces': \"ces_Latn\",\n",
    "    'czk': None,\n",
    "    'slk': \"slk_Latn\",\n",
    "}\n",
    "\n",
    "translation = {}\n",
    "for LANG in SLAVIC_LANGS:\n",
    "    l = ietf_bcp[LANG]\n",
    "    if l is None:\n",
    "        continue\n",
    "    print(LANG)\n",
    "    translation, _ = translate(\"kanapka z łososiem\", \"pol_Latn\", l)\n",
    "    print(translation)\n",
    "    translation, _ = translate(\"медведь со мной\", \"rus_Cyrl\", l)\n",
    "    print(translation)\n",
    "    translation, _ = translate(\"bear with me\", \"eng_Latn\", l)\n",
    "    print(translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7d14f",
   "metadata": {},
   "source": [
    "По фрагменту \"лосось-санск\" видно, что модель (тем более, квантизованная и дистилированная) работает неидеально :)\n",
    "\n",
    "Тем не менее, это даёт нам возможность заметить ещё одну особенность NLLB200: возможность переводить с поломатого русского на нормальный русский."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "cdf5797b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Я видел в меню бутерброд с лососом.']"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation, _ = translate(\"я узрел блюдо 'сендвитч с лососем' внутри меню\", \"rus_Cyrl\", \"rus_Cyrl\")\n",
    "\n",
    "translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdcbe2",
   "metadata": {},
   "source": [
    "### вопрос о методологии\n",
    "\n",
    "Этот раздел вдохновлён работой https://www.dialog-21.ru/media/1335/124.pdf (2010 год), где автор анализирует параллельный чешско-русский корпус и описывает, какими именно различиями в синтаксе обусловлены наиболее частые различия порядка слов.\n",
    "\n",
    "Методика определения различий весьма груба: оба параллельных предложения проходят через PoS-tagging (используя чешский и русский анализаторы соответственно), далее между полученными последовательностями тэгов вычисляется расстояние Левенштейна (например, `NOUN VERB ADJ NOUN` и `NOUN AUX VERB ADJ NOUN` находятся на расстоянии 1 друг от друга). Тем не менее, этот подход оказывается достаточным для выявления многих интересных закономерностей, а выводы автора кажутся мне интересными.\n",
    "\n",
    "Интересно, как соотносятся выводы 2010 года и технологии 2024 года? Иными словами, если бы автор статьи сравнивала не пары ручных переводов, а предложение и его автоперевод? Получилось ли бы у неё найти те же самые закономерности и сделать такие же выводы?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d123b1c",
   "metadata": {},
   "source": [
    "Попробуем воспроизвести пример с pro-drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "14be4aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bel\n",
      "['Пётр сустрэў Эву, і яна расказала яму пра страчанае шаліца.']\n",
      "ukr\n",
      "['Пітер зустрів Еву, і вона розповіла йому про втрачений ожерелок.']\n",
      "rus\n",
      "['Питер встретил Еву, и она рассказала ему о потерянной ожерелье.']\n",
      "bos\n",
      "['Peter je upoznao Eve i ona mu je rekla za izgubljen ogrlicu.']\n",
      "hrv\n",
      "['Peter je upoznao Eve i ona mu je rekla za izgubljen ogrlicu.']\n",
      "srp\n",
      "['Питер је упознао Еву и она му је рекла о изгубљеном огрлицу.']\n",
      "slv\n",
      "['Peter je srečal Eve in mu je povedala o izgubljeni ogrlice.']\n",
      "bul\n",
      "['Питър се срещна с Ева и тя му каза за изгубената огърлица.']\n",
      "mkd\n",
      "['Питер ја запозна Ева и таа му кажа за изгубеното огрлица.']\n",
      "pol\n",
      "['Peter poznał Ewę i ona opowiedziała mu o utraconym naszyjniku.']\n",
      "ces\n",
      "['Peter se setkal s Eve a ona mu řekla o ztraceném náhrdelníku.']\n",
      "slk\n",
      "['Peter sa stretol s Eve a ona mu povedala o stratenej náhrdelnici.']\n"
     ]
    }
   ],
   "source": [
    "for LANG in SLAVIC_LANGS:\n",
    "    l = ietf_bcp[LANG]\n",
    "    if l is None:\n",
    "        continue\n",
    "    print(LANG)\n",
    "    translation, _ = translate(\"Peter met Eve and she told him about the lost necklace.\", \"eng_Latn\", l)\n",
    "    print(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "557388c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bel\n",
      "['Пётар сустрэў Эву і распавёў яму пра страчанае шыі.']\n",
      "ukr\n",
      "['Петро знайшов Єву і розповіла йому про втрачену шейку.']\n",
      "rus\n",
      "['Петр встретил Еву и рассказал ему о потерянной шерсти.']\n",
      "bos\n",
      "['Petar je upoznao Evu i rekla mu da je izgubila vratu.']\n",
      "hrv\n",
      "['Petar je upoznao Evu i ispričao mu o izgubljenom vratu.']\n",
      "srp\n",
      "['Петр је срео Еву и рекао му о изгубљеној врећи.']\n",
      "slv\n",
      "['Peter je srečal Evo in mu povedal, da je izgubila vratu.']\n",
      "bul\n",
      "['Петър се срещнал с Ева и му казал за изгубената му шиша.']\n",
      "mkd\n",
      "['Петар ја сретнал Ева и му кажала за изгубеното јаче.']\n",
      "pol\n",
      "['Peter spotkał Ewę i opowiedziała mu o utraconym sznurze.']\n",
      "ces\n",
      "['Petr potkal Evu a řekl mu o ztraceném náhrdelníku.']\n",
      "slk\n",
      "['Peter sa stretol s Evou a povedal mu o stratenej náhrdelnici.']\n"
     ]
    }
   ],
   "source": [
    "for LANG in SLAVIC_LANGS:\n",
    "    l = ietf_bcp[LANG]\n",
    "    if l is None:\n",
    "        continue\n",
    "    print(LANG)\n",
    "    translation, _ = translate(\"Piotr spotkał Ewę i powiedziała mu o utraconym naszyjniku.\", \"pol_Latn\", l)\n",
    "    print(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "df43f0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bel\n",
      "['\"Вятр занадта моцны\", сказаў ён']\n",
      "['\"Вятр занадта моцны\", сказала яна']\n",
      "ukr\n",
      "['\"Вятр занадто сильний\", сказав він.']\n",
      "['\"Вятр занадто сильний\", сказала вона']\n",
      "rus\n",
      "['\"Ветр слишком сильный\", сказал он.']\n",
      "['\"Ветр слишком сильный\", сказала она.']\n",
      "bos\n",
      "['\"Vjetar je previše jak\", rekao je on.']\n",
      "['\"Vjetar je previše jak\", rekla je ona']\n",
      "hrv\n",
      "['\"Vjetar je previše jak\", rekao je']\n",
      "['\"Vjetar je previše jak\", rekla je ona']\n",
      "srp\n",
      "['\"Вятр је превише јак\", рекао је']\n",
      "['\"Вятр је превише јак\", рекла је']\n",
      "slv\n",
      "['\"Veter je preveč močan\", je rekel']\n",
      "['\"Veter je preveč močan\", je rekla']\n",
      "bul\n",
      "['\"Вятърът е твърде силен\", каза той.']\n",
      "['\"Вятърът е твърде силен\", каза тя.']\n",
      "mkd\n",
      "['\"Ветрот е премногу силен\", рече тој']\n",
      "['\"Ветрот е премногу силен\", рече таа']\n",
      "pol\n",
      "['\"Wiatr jest zbyt silny\", powiedział']\n",
      "['\"Wiatr jest zbyt silny\", powiedziała']\n",
      "ces\n",
      "['\"Vítr je příliš silný\", řekl.']\n",
      "['\"Větr je příliš silný\", řekla.']\n",
      "slk\n",
      "['\"V vetre je príliš silný\", povedal']\n",
      "['\"V vetre je príliš silné\", povedala']\n"
     ]
    }
   ],
   "source": [
    "for LANG in SLAVIC_LANGS:\n",
    "    l = ietf_bcp[LANG]\n",
    "    if l is None:\n",
    "        continue\n",
    "    print(LANG)\n",
    "    translation, _ = translate(\"'The wind is too strong', he said\", \"eng_Latn\", l)\n",
    "    print(translation)\n",
    "    translation, _ = translate(\"'The wind is too strong', she said\", \"eng_Latn\", l)\n",
    "    print(translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbabe7c8",
   "metadata": {},
   "source": [
    "С третьего раза частично получилось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "81f5da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bel\n",
      "['Я спытаў яго, але ён не адказаў']\n",
      "ukr\n",
      "['Я запитав його, але він не відповів.']\n",
      "rus\n",
      "['Я спросил его, но он не ответил.']\n",
      "bos\n",
      "['Pitao sam ga, ali nije odgovorio.']\n",
      "hrv\n",
      "['Pitao sam ga, ali nije odgovorio.']\n",
      "srp\n",
      "['Питала сам га, али није одговорио.']\n",
      "slv\n",
      "['Vprašala sem ga, a ni odgovoril.']\n",
      "bul\n",
      "['Попитах го, но той не отговори.']\n",
      "mkd\n",
      "['Го прашав, но не одговори.']\n",
      "pol\n",
      "['Spytałem go, ale nie odpowiedział.']\n",
      "ces\n",
      "['Zeptal jsem se ho, ale neodpověděl.']\n",
      "slk\n",
      "['Spýtal som sa ho, ale neodpovedal.']\n"
     ]
    }
   ],
   "source": [
    "for LANG in SLAVIC_LANGS:\n",
    "    l = ietf_bcp[LANG]\n",
    "    if l is None:\n",
    "        continue\n",
    "    print(LANG)\n",
    "    translation, _ = translate(\"I asked him, but he did not respond\", \"eng_Latn\", l)\n",
    "    print(translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c697a",
   "metadata": {},
   "source": [
    "Здесь тоже заметна тенденция к pro-drop, хоть и не совсем последовательная."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "26588fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bel\n",
      "['Я бачыў учора цікавы фільм']\n",
      "['Я бачыў цікавы фільм учора.']\n",
      "ukr\n",
      "['Я бачив вчора цікавий фільм.']\n",
      "['Вчора я бачив цікавий фільм.']\n",
      "rus\n",
      "['Я вчера посмотрел интересный фильм.']\n",
      "['Я вчера посмотрел интересный фильм.']\n",
      "bos\n",
      "['Jučer sam vidio zanimljiv film.']\n",
      "['Vidio sam zanimljiv film juče.']\n",
      "hrv\n",
      "['Vidio sam zanimljiv film jučer.']\n",
      "['Vidio sam zanimljiv film jučer.']\n",
      "srp\n",
      "['Учерашњи филм сам видео.']\n",
      "['Идио сам интересантни филм вчера.']\n",
      "slv\n",
      "['Včeraj sem videl zanimivo film.']\n",
      "['Včeraj sem videl zanimivo film.']\n",
      "bul\n",
      "['Вчера видях интересен филм.']\n",
      "['Вчера видях интересен филм.']\n",
      "mkd\n",
      "['Вчера видов интересен филм.']\n",
      "['Вчера видов еден интересен филм.']\n",
      "pol\n",
      "['Widziałem wczoraj ciekawy film.']\n",
      "['Widziałem wczoraj ciekawy film.']\n",
      "ces\n",
      "['Včera jsem viděl zajímavý film.']\n",
      "['Včera jsem viděl zajímavý film.']\n",
      "slk\n",
      "['Včera som videl zaujímavý film.']\n",
      "['Včera som videl zaujímavý film.']\n"
     ]
    }
   ],
   "source": [
    "for LANG in SLAVIC_LANGS:\n",
    "    l = ietf_bcp[LANG]\n",
    "    if l is None:\n",
    "        continue\n",
    "    print(LANG)\n",
    "    translation, _ = translate(\"I've seen an interesting movie yesterday\", \"eng_Latn\", l)\n",
    "    print(translation)\n",
    "    translation, _ = translate(\"Видел вчера интересный фильм.\", \"rus_Cyrl\", l)\n",
    "    print(translation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8f984",
   "metadata": {},
   "source": [
    "Удивительно, но NLLB200 понял, что в русской фразе пропущено именно \"я\", а не \"он\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e3f92",
   "metadata": {},
   "source": [
    "Попробуем перевести с русского на чешский фразы, в которых пропущена копула (но это не очевидно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5df6e91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Psaní článků je těžké.', 'Je zima.', 'Na ulici je světlo.']"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, outputs = translate(\"Писать статьи тяжело. Сейчас холодно. На улице светло.\", \"rus_Cyrl\", \"ces_Latn\", output_attentions=True, return_dict_in_generate=True)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "85cccde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Psaní článků je těžké.', 'Je zima.', 'Venku je světlo.']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, outputs = translate(\"Writing articles is difficult. It's cold. It's bright outside\", \"eng_Latn\", \"ces_Latn\", output_attentions=True, return_dict_in_generate=True)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "0d7d8b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Víme, co je v našem zájmu.',\n",
       " 'Víme, co je v našem zájmu.',\n",
       " 'Vím, že je to pro mě nejlepší.',\n",
       " 'Vím, co je pro mě nejlepší.',\n",
       " 'To mě zajímá.']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, outputs = translate(\n",
    "    \"Мы знаем, какие действия в наших интересах. Мы знаем, какие действия суть в наших интересах. Знаю, что именно в моих интересах. Я знаю, что именно в моих интересах. Это мне любопытно.\", \n",
    "    \"rus_Cyrl\", \"ces_Latn\", \n",
    "    output_attentions=True, return_dict_in_generate=True)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d077d5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wiemy, co jest dla nas najlepsze.',\n",
       " 'Wiemy, co jest dla nas najlepsze.',\n",
       " 'Wiem, że to jest dla mnie najlepsze.',\n",
       " 'Wiem, co jest dla mnie najlepsze.',\n",
       " 'To ciekawe.']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, outputs = translate(\n",
    "    \"Мы знаем, какие действия в наших интересах. Мы знаем, какие действия суть в наших интересах. Знаю, что именно в моих интересах. Я знаю, что именно в моих интересах. Это мне любопытно.\", \n",
    "    \"rus_Cyrl\", \"pol_Latn\", \n",
    "    output_attentions=True, return_dict_in_generate=True)\n",
    "\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf48f45",
   "metadata": {},
   "source": [
    "**Заключение**: хотя по качеству перевода модель явно уступает человеческому (и даже некоторым более специализированным моделям, заточенным под \"крупные\" языки -- например, https://translate.yandex.ru/), на основе таких экспериментов действительно можно сделать более-менее правильные выводы о различиях в синтаксическом строе разных языков."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d02f82c",
   "metadata": {},
   "source": [
    "## Вопрос 2: Починка предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82075d3",
   "metadata": {},
   "source": [
    "Продолжая разбор упомянутой выше статьи -- можем ли мы при помощи NLLB200 и других технологий восстановить опущенную в русском языке копулу?\n",
    "\n",
    "Основной датасет взят из этой же статьи (доступен по адресу https://ufal.mff.cuni.cz/umc/cer/). После того, как все PoS-тэги получены, можно найти примеры предложений с опущеными местоимениями и/или копулой: если в русском предложении нет глаголов, а чешском они есть, то скорее всего дело в zero copula.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ab41fe66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already downloaded a model for the 'cs' language\n",
      "Already downloaded a model for the 'ru' language\n"
     ]
    }
   ],
   "source": [
    "import spacy_udpipe\n",
    "\n",
    "spacy_udpipe.download(\"cs\") # download English model\n",
    "spacy_udpipe.download(\"ru\") # download English model\n",
    "\n",
    "nlp_cs = spacy_udpipe.load(\"cs\")\n",
    "nlp_ru = spacy_udpipe.load(\"ru\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feacc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_sents = []\n",
    "cs_sents = []\n",
    "with open(r\"umc-0.1-corpus\\Czech-Russian.1-1.txt\", \"r\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        cs_text, ru_text = line.split(\"\\t\")\n",
    "        ru_sents.append(ru_text)\n",
    "        cs_sents.append(cs_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ed0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_pos_seq = {\"ru\": [], \"cs\": []}\n",
    "\n",
    "\n",
    "N = 0\n",
    "total = 0\n",
    "\n",
    "with open(r\"umc-0.1-corpus\\Czech-Russian.1-1.txt\", \"r\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        total += 1\n",
    "        # print(line.split(\"\\t\"))\n",
    "        cs_text, ru_text = line.split(\"\\t\")\n",
    "        doc_cs = nlp_cs(cs_text)\n",
    "        doc_ru = nlp_ru(ru_text)\n",
    "        token_pos_seq[\"cs\"].append([token.pos_ for token in doc_cs])\n",
    "        token_pos_seq[\"ru\"].append([token.pos_ for token in doc_ru])\n",
    "        \n",
    "        if token_pos_seq[\"cs\"][-1] == token_pos_seq[\"ru\"][-1]:\n",
    "            N += 1\n",
    "\n",
    "cnt = Counter()\n",
    "\n",
    "for lang in ['cs', 'ru']:\n",
    "    for seq in token_pos_seq[lang]:\n",
    "        cnt.update(seq)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad62680",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_copula_list = []\n",
    "prodrop_list\n",
    "\n",
    "for i, (ru_seq, cs_seq) in enumerate(zip(token_pos_seq['ru'], token_pos_seq['cs'])):\n",
    "    cz_has_copula = (\"VERB\" in cs_seq) or (\"AUX\" in cs_seq)\n",
    "    ru_has_copula = (\"VERB\" in ru_seq) or (\"AUX\" in ru_seq)\n",
    "    if cz_has_copula and not ru_has_copula:\n",
    "        zero_copula_list.append((ru_seq, cs_seq, ru_sents[i], cs_sents[i]))\n",
    "    cz_has_pronoun = (\"PRON\" in cs_seq)\n",
    "    ru_has_pronoun = (\"PRON\" in ru_seq)\n",
    "    if ru_has_pronoun and not cz_has_pronoun:\n",
    "        prodrop_list.append((ru_seq, cs_seq, ru_sents[i], cs_sents[i]))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da588bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1f44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"zero_copula_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(zero_copula_list, f)\n",
    "\n",
    "with open(\"prodrop_list.pkl\", \"wb\") as f:\n",
    "    pickle.dump(prodrop_list, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "83b10951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"zero_copula_list.pkl\", \"rb\") as f:\n",
    "    zero_copula_list = pickle.load(f)\n",
    "\n",
    "with open(\"prodrop_list.pkl\", \"rb\") as f:\n",
    "    prodrop_list = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6a25f505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4573, 17962)"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zero_copula_list), len(prodrop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8338a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f5d8d2a",
   "metadata": {},
   "source": [
    "### Стратегии возврата копулы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8b9495",
   "metadata": {},
   "source": [
    "Первая стратегия хорошо работает с предложениями вида \"X - это Y\":\n",
    "1) втыкиваем слово \"являться\" вместо дефиса\n",
    "\n",
    "2) запрещаем декодеру использовать токен \"-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "91b9fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_words_ids = [tokenizer.encode(word, add_special_tokens=False) for word in \"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "f11d28ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Германия , Франция и Италия являются богатыми странами .']"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, outputs = translate(\n",
    "    \"Германия , Франция и Италия - богатые страны .\".replace(\" - \", \"являться\"), \n",
    "    \"rus_Cyrl\", \"rus_Cyrl\", \n",
    "    output_attentions=True, return_dict_in_generate=True,\n",
    "    bad_words_ids = bad_words_ids\n",
    ")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94787bd4",
   "metadata": {},
   "source": [
    "Вторая стратегия:\n",
    "\n",
    "1) просто вставляем глагол-связку в конец предложения\n",
    "\n",
    "2) Какое должно быть время для глагола-связки? Перебираем несколько основных вариантов: \"являться\", \"является\", \"было\". В дальнейшем можно несложным образом заменить \"был\" на \"есть\", чтобы вернуть предложение в настоящее время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "12d2a7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "На улицах необузданное распространение пессимизма .\n",
      "['На улицах было бесконечное распространение пессимизма.', 'На улицах бесконечное распространение пессимизма.', 'На улицах необузданное распространение пессимизма.']\n",
      "\n",
      "\n",
      "У Европы впереди два пути .\n",
      "['Европа имеет два пути.', 'У Европы есть два пути.', 'У Европы были два пути.']\n",
      "\n",
      "\n",
      "Жозе Бове против бедных\n",
      "['Джозе Бове была против бедных.', 'Джозе Боуэ был против бедных.', 'Джозе Боу был против бедных.', 'Джозе Бове против бедных.', 'Джозе Боу против бедняков.']\n",
      "\n",
      "\n",
      "Эта история почти полностью неправдоподобна .\n",
      "['Эта история была почти полностью неправдоподобной.', 'Эта история почти полностью неправда.']\n",
      "\n",
      "\n",
      "Все остальное неправда .\n",
      "['Все остальное неправда.', 'Все остальное было неправдой.']\n",
      "\n",
      "\n",
      "Что же в этом привлекательного ?\n",
      "['Что было привлекательно в этом?', 'Что в этом привлекательно?', 'Что же привлекательно в этом?']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for entry in zero_copula_list[100:111]:\n",
    "    ru_text, cs_text = entry[2].strip(), entry[3].strip()\n",
    "    ru_text = ru_text.replace(' – ', ' - ').replace(' : ', ' - ')\n",
    "    if \" - \" in ru_text:\n",
    "        continue\n",
    "    print(ru_text)\n",
    "    variants = set()\n",
    "\n",
    "    for sent_add_cand in \"являться является был было была были\".split(): \n",
    "            # for replacement in [\"\", \" - \"]:\n",
    "            res, _ = translate(\n",
    "                ru_text[:-1] + \" \" + sent_add_cand + \".\",\n",
    "                \"rus_Cyrl\", \"rus_Cyrl\",\n",
    "                output_attentions=0, return_dict_in_generate=1)\n",
    "            variants.add(res[0])\n",
    "    print(list(variants))\n",
    "    print()\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c511b54",
   "metadata": {},
   "source": [
    "Третья стратегия требует бОльших ресурсов:\n",
    "\n",
    "1) делаем разбор предложения через udpipe\n",
    "\n",
    "2) проверяем, есть ли там токены со связями типа `cop`, `nsubj` или `csubj`\n",
    "\n",
    "3) вставляем глагол-связку вместо `cop` или перед `nsubj` или `csubj`. Какое должно быть время для глагола-связки? Перебираем четыре основных варианта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "c1f0aab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сколько платить , еще не решено .\n",
      "['Сколько придется заплатить , пока не решено .', 'Пока не решено , сколько заплатить .', 'Сколько будет платить , пока не решено .', 'Сколько заплатить , пока не решено .', 'Сколько было заплачено , еще не решено .', 'Сколько стоит заплатить , пока не решено .', 'Сколько будет платить , еще не решено .']\n",
      "\n",
      "Забыть эту поездку трудно.\n",
      "['Это было трудно забыть.', 'Это трудно забыть.', 'О том путешествии трудно забыть.', 'Очень трудно забыть о поездке.', 'Это будет трудно забыть.']\n",
      "\n",
      "Нужны компетентные профессионалы .\n",
      "['Нужны будут компетентные профессионалы .', 'Нужны были компетентные профессионалы .', 'необходимы компетентные профессионалы .', 'Должны быть компетентные профессионалы .', 'Нужны компетентные профессионалы .', 'нужны были компетентные профессионалы .']\n",
      "\n",
      "На улицах необузданное распространение пессимизма\n",
      "['На улицах будет бескорыстно распространяться пессимизм', 'На улицах бескорыстно распространялся пессимизм', 'На улицах есть бесконечный распространение пессимизма', 'На улицах бывает бескорыстное распространение пессимизма', 'На улицах будет бесконечный распространение пессимизма', 'На улицах неуместно распространяться пессимизм', 'На улицах бескорыстным является распространение пессимизма', 'На улицах был бесконечный распространение пессимизма']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ru_text in [\n",
    "    \"Сколько платить , еще не решено .\",\n",
    "    \"Забыть эту поездку трудно.\",\n",
    "    \"Нужны компетентные профессионалы .\",\n",
    "    \"На улицах необузданное распространение пессимизма\"\n",
    "]:\n",
    "    print(ru_text)\n",
    "    doc = nlp_ru(ru_text)\n",
    "    variants = set()\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.dep_ in ['cop', 'nsubj', 'csubj', 'ROOT']:\n",
    "            if token.dep_ == 'cop':\n",
    "                src_text = token.text\n",
    "                ru_text_cand = ru_text\n",
    "            else:\n",
    "                ru_text_cand = ru_text.replace(token.text, f\"<subj> {token.text}\")\n",
    "                src_text = \"<subj>\"\n",
    "            # for replacement_cand in [\"будет\", \"было\", \"являться\", \"является\"]:\n",
    "            # for replacement_cand in [\"являться\", \"является\", \"is\"]:\n",
    "            for replacement_cand in [\"является\", \"будет\", \"было\", \"являться\"]:\n",
    "                ru_text_cand2 = ru_text_cand.replace(src_text, replacement_cand)\n",
    "                # print(ru_text_cand2)\n",
    "                res, _ = translate(\n",
    "                    ru_text_cand2,\n",
    "                    \"rus_Cyrl\", \"rus_Cyrl\",\n",
    "                    output_attentions=0, return_dict_in_generate=1,\n",
    "                    bad_words_ids=bad_words_ids\n",
    "                )\n",
    "                variants.add(res[0])\n",
    "    print(list(variants))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849706ff",
   "metadata": {},
   "source": [
    "Увы, незаметно, чтобы эта более сложная стратегия давала здесь какой-то заметный выигрыш (возможно даже наоборот).\n",
    "\n",
    "Также нужно обратить внимание на большую \"хрупкость\" модели: даже наличие/отсутствие финальной точки может сильно повлиять на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "1f96488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['На улицах бескорыстным является распространение пессимизма']\n",
      "['На улицах будет бескорыстно распространяться пессимизм']\n",
      "['На улицах бескорыстно распространялся пессимизм']\n",
      "['На улицах бескорыстно распространяется пессимизм']\n"
     ]
    }
   ],
   "source": [
    "for replacement_cand in [\"является\", \"будет\", \"было\", \"есть\"]:\n",
    "\n",
    "    ru_text = \"На улицах необузданное <nsubj> распространение пессимизма .\".replace(\"<nsubj>\", replacement_cand)\n",
    "\n",
    "    res, _ = translate(\n",
    "        ru_text[:-1],\n",
    "        \"rus_Cyrl\", \"rus_Cyrl\",\n",
    "        output_attentions=0, return_dict_in_generate=1,\n",
    "        bad_words_ids=bad_words_ids\n",
    "    )\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f84472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eeb4a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dae9f9d4",
   "metadata": {},
   "source": [
    "### Стратегии возврата местоимения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee1e217",
   "metadata": {},
   "source": [
    "Попробуем более точно выделять случаи с пропущенным местоимением. Будем при помощи udpipe находить глаголы, с которыми не связаны слова в именительном падеже (deprel-отношение `nsubj`)\n",
    "т.е. при помощи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "7e4bb81e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10368, 17962)"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prodrop_list_filtered = []\n",
    "\n",
    "for entry in prodrop_list:\n",
    "    ru_text, cs_text = entry[2].strip(), entry[3].strip()\n",
    "    doc = nlp_cs(cs_text)\n",
    "    for token in doc:\n",
    "        if token.morph and token.pos_ in [\"VERB\"]:\n",
    "            nsubj_found = False\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"nsubj\" and child.head.i == token.i:\n",
    "                    nsubj_found = True\n",
    "                    break\n",
    "            if not nsubj_found:\n",
    "                prodrop_list_filtered.append(entry)\n",
    "                break\n",
    "                \n",
    "len(prodrop_list_filtered), len(prodrop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a58c9d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Многие пакистанцы , лишённые иллюзий в отношении политического класса Пакистана , молчаливо согласились с его приходом к власти , думая , что он сможет что -то изменить .\n",
      "Mnoho Pákistánců rozčarovaných pákistánskou politickou garniturou mlčelo v domnění , že by mohl svým slibům dostát .\n",
      "\n",
      "mohl VERB acl domnění\n",
      "{'Gender': 'Masc', 'Number': 'Sing', 'Polarity': 'Pos', 'Tense': 'Past', 'VerbForm': 'Part', 'Voice': 'Act'}\n",
      "[,, že, by, dostát]\n",
      "['Mnoho Pákistánců zklamaných pakistánskou politickou garniturou mlčel , že bych mohl splnit své sliby .', 'Mnoho Pákistánců , kteří byli zklamaní pákistánskou politickou garniturou , mlčel , protože si mysleli , že může dosáhnout svých slibů .', 'Mnoho Pákistánců zklamaných pákistánskou politickou garniturou mlčel , že by mohla splnit své sliby .', 'Mnoho Pákistánců , kteří byli zklamaní pakistánskou politickou šatou , mlčel , že by mohl splnit své sliby .', 'Mnoho Pákistánců , kteří byli zklamaní pákistánskou politickou garniturou , mlčel , že by mohl splnit své sliby .']\n",
      "Террористические атаки в Америке 11 сентября 2001 года позволили Мушаррафу попасть в центр внимания на международной арене , поскольку он согласился уничтожить Талибан и поддержать войну с терроризмом , возглавляемую Соединёнными Штатами .\n",
      "Teroristické útoky na Spojené státy z 11 . září 2001 přivedly Mušarafa do záře mezinárodních reflektorů , neboť souhlasil s odstavením Talibanu a podporou Spojenými státy vedené války s terorismem .\n",
      "\n",
      "souhlasil VERB conj přivedly\n",
      "{'Aspect': 'Imp', 'Gender': 'Masc', 'Number': 'Sing', 'Polarity': 'Pos', 'Tense': 'Past', 'VerbForm': 'Part', 'Voice': 'Act'}\n",
      "[,, neboť, odstavením]\n",
      "['Teroristická útoky na Spojené státy ze dne 11. září 2001 musharraf dostala do světla mezinárodních světlometů , protože souhlasila s odstavením Talibanu a podporou války proti terorismu vedené Spojenými státy .', 'Teroristické útoky na Spojené státy ze dne 11. září 2001 Musharraf dostal do světla mezinárodních světlometů , protože souhlasil s odstavením Talibanu a podporou války proti terorismu vedené Spojenými státy .', 'Teroristické útoky na Spojené státy ze dne 11. září 2001 musharraf dostal do světla mezinárodních reflektorů , protože jsem souhlasil s odstavením Talibanu a podporou americké války proti terorismu .']\n",
      "Например , он сотрудничал с исламистскими политическими силами ( которые в 2004 г . проголосовали за конституционные изменения , узаконивающие его положение и действия ) .\n",
      "Uzavřel například spojenectví s islamistickými politickými silami ( které v roce 2004 hlasovaly pro ústavní změny legitimizující jeho postavení a konání ) .\n",
      "\n",
      "Uzavřel VERB ROOT Uzavřel\n",
      "{'Gender': 'Masc', 'Number': 'Sing', 'Polarity': 'Pos', 'Tense': 'Past', 'VerbForm': 'Part', 'Voice': 'Act'}\n",
      "[například, spojenectví, .]\n",
      "['Například uzavřel spojenectví s islamistickými politickými silami (které v roce 2004 hlasovaly pro ústavní změny , které legitimizovaly jeho postavení a jednání).']\n",
      "Историческое решение самого Верховного суда , которое Мушаррафу оставалось только принять , восстановило главного судью в его должности в июле .\n",
      "Historickým rozhodnutím , které Mušarafovi prakticky nezbývalo než přijmout , sám Nejvyšší soud v červenci opětovně jmenoval původního hlavního soudce .\n",
      "[]\n",
      "Несмотря на обещания оставить свою военную должность , в случае если его изберут президентом , его репутация не исполнять свои обещания не давала покоя судебной власти .\n",
      "Oznámil sice , že odstoupí z vojenského postu , „ pokud “ bude zvolen prezidentem , avšak jeho dosavadní bilance porušených slibů soudcovský stav děsila .\n",
      "\n",
      "odstoupí VERB acl sice\n",
      "{'Aspect': 'Perf', 'Mood': 'Ind', 'Number': 'Sing', 'Person': '3', 'Polarity': 'Pos', 'Tense': 'Pres', 'VerbForm': 'Fin', 'Voice': 'Act'}\n",
      "[,, že, postu, ,, „, zvolen]\n",
      "['I když oznámil , že odejde z vojenského úřadu , pokud bude zvolen prezidentem , jeho dosud nedodržané sliby vystrašily soudní postavení .', 'Ačkoli oznámil , že opustí vojenskou funkci , pokud bude zvolen prezidentem , jeho dosud nedodržané sliby děsily soudní postavu .', 'I když oznámil , že odejde z vojenského úřadu , pokud bude zvolen prezidentem , ale jeho dosud porušení slibů vystrašilo soudní postavení .']\n",
      "В случае продолжительных протестов и потенциального насилия высшие военные командные чины могут решить сместить Мушаррафа , что не станет чем - то беспрецедентным в хронически неспокойной истории Пакистана .\n",
      "V případě přetrvávajících protestů a potenciálního násilí mohou nejvyšší vojenští velitelé rozhodnout , že hodí Mušarafa přes palubu – takové rozhodnutí by v chronicky rozbouřených dějinách Pákistánu rozhodně nebylo bezprecedentní .\n",
      "[]\n",
      "По мере того , как начинаются хаос и беспорядок , мы не должны упускать из виду частичную ответственность президента Первеза Мушаррафа за этот поворот событий .\n",
      "Jak propuká chaos a zmatek , neměli bychom pouštět ze zřetele částečnou zodpovědnost prezidenta Parvíze Mušarafa za tento zvrat událostí .\n",
      "\n",
      "neměli VERB ROOT neměli\n",
      "{'Animacy': 'Anim', 'Gender': 'Masc', 'Number': 'Plur', 'Polarity': 'Neg', 'Tense': 'Past', 'VerbForm': 'Part', 'Voice': 'Act'}\n",
      "[propuká, bychom, pouštět, .]\n",
      "['Jakmile nastane chaos a zmatek , neměli bychom přehlížet částečnou odpovědnost prezidenta Parveze Musharafa za to , co se stalo .', 'Když nastane chaos a zmatek , neměli bychom přehlížet částečnou odpovědnost prezidenta Parvize Musharafa za to , co se stalo .', 'Když nastane chaos a zmatek , neměli bychom přehlížet částečnou odpovědnost prezidenta Parveze Musharafa za to , co se stalo .']\n",
      "Она в значительной степени действовала согласно своему обещанию .\n",
      "Velkou měrou svůj slib splnila .\n",
      "\n",
      "splnila VERB ROOT splnila\n",
      "{'Aspect': 'Perf', 'Gender': 'Fem,Neut', 'Number': 'Plur,Sing', 'Polarity': 'Pos', 'Tense': 'Past', 'VerbForm': 'Part', 'Voice': 'Act'}\n",
      "[měrou, slib, .]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "('1', 'Plur,Sing')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[437], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pers \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m123\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     38\u001b[0m         key \u001b[38;5;241m=\u001b[39m (pers, feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 39\u001b[0m         possible_pronouns \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m CZ_PRONOUNS[key]\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m one_pronoun \u001b[38;5;129;01min\u001b[39;00m possible_pronouns:\n\u001b[0;32m     41\u001b[0m     cs_text_cand \u001b[38;5;241m=\u001b[39m cs_text\u001b[38;5;241m.\u001b[39mreplace(token\u001b[38;5;241m.\u001b[39mtext, one_pronoun \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m token\u001b[38;5;241m.\u001b[39mtext)\n",
      "\u001b[1;31mKeyError\u001b[0m: ('1', 'Plur,Sing')"
     ]
    }
   ],
   "source": [
    "CZ_PRONOUNS = {\n",
    "    (\"1\", \"Sing\"): [\"já\"],\n",
    "    (\"2\", \"Sing\"): [\"ty\"],\n",
    "    (\"3\", \"Sing\"): [\"on\", \"ona\", \"ono\"],\n",
    "    (\"1\", \"Plur\"): [\"my\"],\n",
    "    (\"2\", \"Plur\"): [\"vy\"],\n",
    "    (\"3\", \"Plur\"): [\"oni\", \"one\", \"ona\"]\n",
    "}\n",
    "\n",
    "for entry in prodrop_list_filtered[:11]:\n",
    "    ru_text, cs_text = entry[2].strip(), entry[3].strip()\n",
    "    doc = nlp_cs(cs_text)\n",
    "    print(ru_text)\n",
    "    print(cs_text)\n",
    "    variants = set()\n",
    "    for token in doc:\n",
    "        if token.morph and token.pos_ in [\"VERB\"]:\n",
    "            feature_dict = dict(item.split(\"=\") for item in str(token.morph).split(\"|\"))\n",
    "            if feature_dict.get('VerbForm') == \"Inf\":\n",
    "                break\n",
    "\n",
    "            nsubj_found = False\n",
    "            for child in token.children:\n",
    "                if child.dep_ == \"nsubj\" and child.head.i == token.i:\n",
    "                    nsubj_found = True\n",
    "                    break\n",
    "            if not nsubj_found:\n",
    "                print()\n",
    "                print(token.text, token.pos_, token.dep_, token.head)\n",
    "                print(feature_dict)\n",
    "                print(list(token.children))\n",
    "                if \"Person\" in feature_dict:\n",
    "                    key = (feature_dict[\"Person\"], feature_dict[\"Number\"])\n",
    "                    possible_pronouns = CZ_PRONOUNS[key]\n",
    "                else:\n",
    "                    possible_pronouns = []\n",
    "                    for pers in \"123\":\n",
    "                        key = (pers, feature_dict[\"Number\"])\n",
    "                        possible_pronouns += CZ_PRONOUNS[key]\n",
    "                for one_pronoun in possible_pronouns:\n",
    "                    cs_text_cand = cs_text.replace(token.text, one_pronoun + \" \" + token.text)\n",
    "                    # print(cs_text_cand)\n",
    "                    res, _ = translate(\n",
    "                        cs_text_cand,\n",
    "                        \"ces_Latn\", \"ces_Latn\",\n",
    "                        output_attentions=0, return_dict_in_generate=1,\n",
    "                        num_beams=8,\n",
    "                        do_sample=True,  # Enable sampling\n",
    "                        top_k=50,\n",
    "                        top_p=0.95,  # Use nucleus sampling\n",
    "                        temperature=0.9,  # Slight randomness\n",
    "                        num_return_sequences=8  # Return 5 variants\n",
    "                    )\n",
    "                    # print(res)\n",
    "                    variants |= set(res)\n",
    "    print(list(variants))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b00ca4",
   "metadata": {},
   "source": [
    "Детекция пропуска местоименний через udpipe работает неплохо, она правильно находит глагол, у которого нет субъекта.\n",
    "\n",
    "Добавить местоимение оказывается нелегко: даже с высокой температурой и несколькими кандидатами из beam search, модель очень не хочет генерировать предложения не на \"стандартном\" чешском. Возможно, стоит попробовать подставлять \"фальшивые\" имена вместо местоимений, а затем заменять их на правильные местоимения на этапе постпроцессинга.\n",
    "\n",
    "Что-то похожее наблюдалось и для русского языка. Обычно хорошие результаты получаются либо за счёт парафраза (напр., переделка \"Одна альтернатива - это X в \"Одна альтернатива заключается в X\"), либо за счёт изменения грамматического времени на прошлое или будущее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257f0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:udpip]",
   "language": "python",
   "name": "conda-env-udpip-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
